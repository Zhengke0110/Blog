---
title: éƒ¨ç½²ï¼šAIè§†é¢‘ç”Ÿæˆæ¨¡å‹ CogVideoX-5b æºç éƒ¨ç½²
date: 2025-08-15
type: notes-llm
---

CogVideoX-5b æ˜¯ç”±æ¸…åå¤§å­¦å’Œæ™ºè°± AI è”åˆå¼€å‘çš„å¼€æºå¤šæ¨¡æ€è§†é¢‘ç”Ÿæˆå¤§æ¨¡å‹ï¼ŒåŸºäº 3D å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆ3D VAEï¼‰å’Œæ‰©æ•£å˜æ¢å™¨ï¼ˆDiTï¼‰æ¶æ„ã€‚è¯¥æ¨¡å‹æ”¯æŒä¸­è‹±æ–‡æ–‡æœ¬åˆ°è§†é¢‘çš„ç”Ÿæˆï¼Œèƒ½å¤Ÿç”Ÿæˆæ—¶é•¿ 6 ç§’ã€åˆ†è¾¨ç‡ 720x480ã€å¸§ç‡ 8fps çš„é«˜è´¨é‡è§†é¢‘å†…å®¹ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•ä»æºç è¿›è¡Œæœ¬åœ°åŒ–éƒ¨ç½²å’Œé…ç½®ä¼˜åŒ–ã€‚

## ç³»ç»Ÿè¦æ±‚

### æ ¸å¿ƒæŠ€æœ¯è§„æ ¼

CogVideoX-5b æ˜¯ä¸€ä¸ªæ‹¥æœ‰ **50 äº¿å‚æ•°** çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œé‡‡ç”¨äº†ä»¥ä¸‹æ ¸å¿ƒæŠ€æœ¯ï¼š

- **æ¨¡å‹æ¶æ„**: 3D å˜åˆ†è‡ªç¼–ç å™¨ (3D VAE) + æ‰©æ•£å˜æ¢å™¨ (DiT)
- **è¾“å‡ºè§„æ ¼**: 6 ç§’è§†é¢‘ï¼Œ720Ã—480 åˆ†è¾¨ç‡ï¼Œ8fps å¸§ç‡ï¼Œå…± 48 å¸§
- **è¯­è¨€æ”¯æŒ**: ä¸­æ–‡å’Œè‹±æ–‡åŒè¯­æ–‡æœ¬æç¤ºè¯
- **æ¨ç†ç²¾åº¦**: æ”¯æŒ FP16 å’Œ BF16 æ··åˆç²¾åº¦æ¨ç†

### ç¡¬ä»¶è¦æ±‚è¯¦è§£

#### GPU æ˜¾å­˜éœ€æ±‚åˆ†æ

ä¸åŒä½¿ç”¨åœºæ™¯çš„æ˜¾å­˜è¦æ±‚ï¼š

| ä½¿ç”¨æ¨¡å¼     | æœ€ä½æ˜¾å­˜ | æ¨èæ˜¾å­˜ | æ¨è GPU å‹å·        | ç”Ÿæˆè´¨é‡         |
| ------------ | -------- | -------- | -------------------- | ---------------- |
| **å¿«é€Ÿä½“éªŒ** | 8GB      | 12GB     | RTX 4070, RTX 3080   | åŸºç¡€è´¨é‡ (13 å¸§) |
| **æ ‡å‡†ä½¿ç”¨** | 12GB     | 18GB     | RTX 4080, RTX 4070Ti | æ ‡å‡†è´¨é‡ (25 å¸§) |
| **æœ€ä½³è´¨é‡** | 18GB     | 24GB+    | RTX 4090, A100, H100 | é«˜è´¨é‡ (49 å¸§)   |

> **æ³¨æ„**: å®é™…æ˜¾å­˜å ç”¨ä¼šæ ¹æ®ç”Ÿæˆå‚æ•°åŠ¨æ€å˜åŒ–ã€‚å¯ç”¨å†…å­˜ä¼˜åŒ–åŠŸèƒ½å¯é™ä½çº¦ 20-30% çš„æ˜¾å­˜éœ€æ±‚ã€‚

#### ç³»ç»Ÿé…ç½®è¦æ±‚

- **CPU**: Intel i5-8400 / AMD Ryzen 5 3600 æˆ–æ›´é«˜
- **å†…å­˜**:
  - æœ€ä½: 16GB (ä»…é™å¿«é€Ÿä½“éªŒæ¨¡å¼)
  - æ¨è: 32GB (æ ‡å‡†ä½¿ç”¨)
  - æœ€ä½³: 64GB+ (é«˜è´¨é‡ç”Ÿæˆ + å¤šä»»åŠ¡å¤„ç†)
- **å­˜å‚¨**:
  - ç³»ç»Ÿç›˜: è‡³å°‘ 20GB å¯ç”¨ç©ºé—´
  - æ¨¡å‹å­˜å‚¨: 50GB+ (CogVideoX-5b æ¨¡å‹çº¦ 18GB)
  - è¾“å‡ºç©ºé—´: å»ºè®®é¢„ç•™ 50GB+ (ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶)
- **CUDA**: æ”¯æŒ CUDA 11.8 æˆ– 12.1+ (å¿…é¡»ä¸ PyTorch ç‰ˆæœ¬åŒ¹é…)

#### ç½‘ç»œè¦æ±‚

- **åˆæ¬¡éƒ¨ç½²**: ç¨³å®šç½‘ç»œè¿æ¥ï¼Œç”¨äºä¸‹è½½ 18GB æ¨¡å‹æ–‡ä»¶
- **é•œåƒåŠ é€Ÿ**: å»ºè®®é…ç½® HuggingFace é•œåƒæº (å¦‚ hf-mirror.com)
- **å¸¦å®½å»ºè®®**: 100Mbps+ (åŠ å¿«æ¨¡å‹ä¸‹è½½é€Ÿåº¦)

### è½¯ä»¶ç¯å¢ƒè¦æ±‚

#### Python ç¯å¢ƒ

- **Python ç‰ˆæœ¬**: 3.8 - 3.11 (æ¨è 3.10)
- **åŒ…ç®¡ç†å™¨**: pip æˆ– conda (æ¨èä½¿ç”¨ conda è¿›è¡Œç¯å¢ƒéš”ç¦»)

#### æ·±åº¦å­¦ä¹ æ¡†æ¶

- **PyTorch**: 2.0.0+ (å¿…é¡»æ”¯æŒ CUDA)
- **æ ¸å¿ƒä¾èµ–**:
  - `diffusers >= 0.30.0` (è§†é¢‘ç”Ÿæˆç®¡é“)
  - `transformers >= 4.44.0` (æ–‡æœ¬ç¼–ç å™¨)
  - `accelerate >= 0.20.0` (åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ)

### æ€§èƒ½é¢„ä¼°

#### ç”Ÿæˆæ—¶é—´å‚è€ƒ (å•ä¸ªè§†é¢‘)

| GPU å‹å· | 13 å¸§æ¨¡å¼ | 25 å¸§æ¨¡å¼   | 49 å¸§æ¨¡å¼   |
| -------- | --------- | ----------- | ----------- |
| RTX 4090 | ~1-2 åˆ†é’Ÿ | ~2-3 åˆ†é’Ÿ   | ~4-6 åˆ†é’Ÿ   |
| RTX 4080 | ~2-3 åˆ†é’Ÿ | ~3-5 åˆ†é’Ÿ   | ~6-9 åˆ†é’Ÿ   |
| RTX 4070 | ~3-5 åˆ†é’Ÿ | ~5-8 åˆ†é’Ÿ   | ~10-15 åˆ†é’Ÿ |
| A100     | ~1 åˆ†é’Ÿ   | ~1-2 åˆ†é’Ÿ   | ~2-4 åˆ†é’Ÿ   |

> **æç¤º**: å®é™…ç”Ÿæˆæ—¶é—´å—æç¤ºè¯å¤æ‚åº¦ã€æ¨ç†æ­¥æ•°ç­‰å‚æ•°å½±å“ã€‚é¦–æ¬¡è¿è¡Œéœ€è¦é¢å¤–çš„æ¨¡å‹åŠ è½½æ—¶é—´ã€‚

## éƒ¨ç½²æ­¥éª¤

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n cogvideox python=3.10 -y
conda activate cogvideox

# å®‰è£…CUDAç›¸å…³ä¾èµ–
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### CUDA ç‰ˆæœ¬ç¡®è®¤

åœ¨å®‰è£… PyTorch ä¹‹å‰ï¼Œè¯·ç¡®è®¤æ‚¨çš„ CUDA ç‰ˆæœ¬ï¼š

```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi
```

### 2. å®‰è£…ä¾èµ–

ç›´æ¥å®‰è£…æ‰€éœ€çš„ Python ä¾èµ–åŒ…ï¼š

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–åŒ…
pip install diffusers[torch]>=0.30.0
pip install transformers>=4.44.0
pip install accelerate>=0.20.0
pip install imageio-ffmpeg
pip install safetensors

# å®‰è£…ModelScopeå’ŒHuggingFaceå·¥å…·
pip install modelscope
pip install huggingface_hub

# å®‰è£…å…¶ä»–å¿…éœ€ä¾èµ–
pip install pillow
pip install numpy
pip install opencv-python
```

#### ä¾èµ–åŒ…è¯´æ˜

| åŒ…å              | ç‰ˆæœ¬è¦æ±‚ | ä½œç”¨                 |
| ----------------- | -------- | -------------------- |
| `diffusers`       | >=0.30.0 | è§†é¢‘ç”Ÿæˆç®¡é“æ ¸å¿ƒåº“   |
| `transformers`    | >=4.44.0 | æ–‡æœ¬ç¼–ç å™¨           |
| `accelerate`      | >=0.20.0 | æ¨¡å‹åŠ é€Ÿå’Œå†…å­˜ä¼˜åŒ–   |
| `torch`           | >=2.0.0  | æ·±åº¦å­¦ä¹ æ¡†æ¶         |
| `imageio-ffmpeg`  | æœ€æ–°     | è§†é¢‘æ–‡ä»¶å¤„ç†         |
| `safetensors`     | æœ€æ–°     | å®‰å…¨çš„æ¨¡å‹æ–‡ä»¶æ ¼å¼   |
| `modelscope`      | æœ€æ–°     | ModelScope å¹³å°å·¥å…·  |
| `huggingface_hub` | æœ€æ–°     | HuggingFace å¹³å°å·¥å…· |

#### éªŒè¯ä¾èµ–å®‰è£…

```bash
# éªŒè¯å…³é”®åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "import diffusers; print('Diffusers:', diffusers.__version__)"
python -c "import transformers; print('Transformers:', transformers.__version__)"
python -c "import accelerate; print('Accelerate:', accelerate.__version__)"
```

### 3. ä¸‹è½½æ¨¡å‹

```bash
# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p models

# è¿›å…¥æ¨¡å‹ç›®å½•
cd models
```

#### æ–¹æ³•ä¸€ï¼šModelScope ä¸‹è½½ï¼ˆæ¨èï¼‰

```bash
# å¦‚æœè¿˜æ²¡å®‰è£…ModelScope
pip install modelscope

# ä¸‹è½½CogVideoX-5bæ¨¡å‹
modelscope download --model ZhipuAI/CogVideoX-5b --local_dir ./CogVideoX-5b

# éªŒè¯ä¸‹è½½å®Œæˆ
ls -la ./CogVideoX-5b/
```

![ModelScope ](/images/notes/llm/Deploy-CogVideoX-5b/download.png)

#### æ–¹æ³•äºŒï¼šHuggingFace ä¸‹è½½

```bash
# å®‰è£…huggingface-hub CLIå·¥å…·
pip install huggingface_hub[cli]

# ä¸‹è½½æ¨¡å‹
huggingface-cli download THUDM/CogVideoX-5b --local-dir ./CogVideoX-5b

# è®¾ç½®é•œåƒåŠ é€Ÿï¼ˆå¯é€‰ï¼Œå›½å†…ç”¨æˆ·ï¼‰
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download THUDM/CogVideoX-5b --local-dir ./CogVideoX-5b
```

### 4. åˆ›å»ºç¯å¢ƒæ£€æŸ¥è„šæœ¬

åˆ›å»º `check_environment.py` æ–‡ä»¶ï¼Œç”¨äºæ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå’Œä¾èµ–åŒ…ï¼š

```python
import torch
import os
import sys
import shutil

def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    print("=== ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥ ===")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    if python_version < (3, 8):
        print("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦3.8+")
        return False
    else:
        print("âœ… Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚")

    # æ£€æŸ¥CUDA
    cuda_available = torch.cuda.is_available()
    print(f"CUDAå¯ç”¨: {cuda_available}")
    if cuda_available:
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        gpu_count = torch.cuda.device_count()
        print(f"GPUæ•°é‡: {gpu_count}")
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
            print(f"GPU {i}: {gpu_name}, {gpu_memory:.1f} GB")
            if gpu_memory < 16:
                print(f"âŒ GPU {i} æ˜¾å­˜å¯èƒ½ä¸è¶³ï¼Œå»ºè®®18GB+")
            else:
                print(f"âœ… GPU {i} æ˜¾å­˜å……è¶³")
    else:
        print("âŒ å°†ä½¿ç”¨CPUæ¨¡å¼ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

    return True

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("\n=== ä¾èµ–åŒ…æ£€æŸ¥ ===")

    required_packages = [
        ("torch", "2.0.0"),
        ("diffusers", "0.30.0"),
        ("transformers", "4.44.0"),
        ("accelerate", "0.20.0"),
        ("imageio-ffmpeg", None),
        ("safetensors", None),
        ("modelscope", None),
        ("huggingface_hub", None)
    ]

    all_ok = True
    for package, min_version in required_packages:
        try:
            if package == "imageio-ffmpeg":
                __import__("imageio_ffmpeg")
            elif package == "huggingface_hub":
                __import__("huggingface_hub")
            else:
                __import__(package)

            module = __import__(package.replace("-", "_"))
            version = getattr(module, '__version__', 'unknown')
            print(f"âœ… {package}: {version}")
        except ImportError:
            print(f"âŒ {package}: æœªå®‰è£…")
            all_ok = False

    return all_ok

def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
    print("\n=== ç£ç›˜ç©ºé—´æ£€æŸ¥ ===")

    total, used, free = shutil.disk_usage(".")
    free_gb = free // (1024**3)

    print(f"å¯ç”¨ç£ç›˜ç©ºé—´: {free_gb} GB")

    if free_gb < 10:
        print("âŒ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®è‡³å°‘ä¿ç•™10GBç”¨äºè§†é¢‘ç”Ÿæˆ")
        return False
    else:
        print("âœ… ç£ç›˜ç©ºé—´å……è¶³")
        return True

def check_model_directory():
    """ç®€å•æ£€æŸ¥æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨"""
    print("\n=== æ¨¡å‹ç›®å½•æ£€æŸ¥ ===")

    model_path = "./models/CogVideoX-5b"
    if os.path.exists(model_path):
        # è®¡ç®—æ¨¡å‹æ€»å¤§å°
        total_size = 0
        file_count = 0
        for root, dirs, files in os.walk(model_path):
            for file in files:
                total_size += os.path.getsize(os.path.join(root, file))
                file_count += 1

        total_size_gb = total_size / (1024**3)
        print(f"âœ… æ¨¡å‹ç›®å½•å­˜åœ¨: {model_path}")
        print(f"âœ… æ–‡ä»¶æ•°é‡: {file_count}")
        print(f"âœ… æ€»å¤§å°: {total_size_gb:.2f} GB")

        if total_size_gb < 10:
            print("âŒ æ¨¡å‹å¤§å°å¼‚å¸¸ï¼Œå¯èƒ½ä¸‹è½½ä¸å®Œæ•´")
            return False
        else:
            print("âœ… æ¨¡å‹å¤§å°æ­£å¸¸")
            return True
    else:
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
        print("\nè¯·å…ˆä¸‹è½½æ¨¡å‹:")
        print("# ModelScope ä¸‹è½½ (æ¨è)")
        print("modelscope download --model ZhipuAI/CogVideoX-5b --local_dir ./models/CogVideoX-5b")
        print("\n# HuggingFace ä¸‹è½½")
        print("huggingface-cli download THUDM/CogVideoX-5b --local-dir ./models/CogVideoX-5b")
        return False

def main():
    """ä¸»æ£€æŸ¥å‡½æ•°"""
    print("CogVideoX-5b éƒ¨ç½²ç¯å¢ƒæ£€æŸ¥")
    print("=" * 40)

    # æ‰§è¡Œæ£€æŸ¥
    system_ok = check_system_requirements()
    deps_ok = check_dependencies()
    disk_ok = check_disk_space()
    model_ok = check_model_directory()

    # æ€»ç»“ç»“æœ
    print(f"\n{'='*40}")
    print("ç¯å¢ƒæ£€æŸ¥ç»“æœ:")
    print(f"ç³»ç»Ÿç¯å¢ƒ: {'âœ… é€šè¿‡' if system_ok else 'âŒ å¤±è´¥'}")
    print(f"ä¾èµ–åŒ…: {'âœ… é€šè¿‡' if deps_ok else 'âŒ å¤±è´¥'}")
    print(f"ç£ç›˜ç©ºé—´: {'âœ… é€šè¿‡' if disk_ok else 'âŒ å¤±è´¥'}")
    print(f"æ¨¡å‹æ–‡ä»¶: {'âœ… é€šè¿‡' if model_ok else 'âŒ å¤±è´¥'}")

    overall_status = all([system_ok, deps_ok, disk_ok, model_ok])

    if overall_status:
        print(f"\nâœ… ç¯å¢ƒæ£€æŸ¥å…¨éƒ¨é€šè¿‡ï¼")
    else:
        print(f"\nâŒ ç¯å¢ƒæ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•")

    return overall_status

if __name__ == "__main__":
    main()
```

### 5. åˆ›å»ºè§†é¢‘ç”Ÿæˆè„šæœ¬

åˆ›å»º `generate_video.py` æ–‡ä»¶ï¼Œä¸“æ³¨äºè§†é¢‘ç”ŸæˆåŠŸèƒ½ï¼š

```python
import torch
import os
import argparse
from diffusers import CogVideoXPipeline, CogVideoXDDIMScheduler
from diffusers.utils import export_to_video

def generate_video(prompt, output_path="output.mp4",
                  num_frames=49, num_inference_steps=50,
                  height=480, width=720, guidance_scale=6.0, seed=42):
    """ç”Ÿæˆè§†é¢‘"""

    model_path = "./models/CogVideoX-5b"

    # å¿«é€Ÿæ£€æŸ¥æ¨¡å‹è·¯å¾„
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ: python check_environment.py")
        return False

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"æ­£åœ¨ç”Ÿæˆè§†é¢‘: {prompt}")
    print(f"å‚æ•°: {num_frames}å¸§, {height}x{width}, {num_inference_steps}æ­¥")

    try:
        # åŠ è½½æ¨¡å‹
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        
        # åŠ è½½è°ƒåº¦å™¨
        scheduler = CogVideoXDDIMScheduler.from_pretrained(
            model_path, 
            subfolder="scheduler"
        )
        
        # åŠ è½½pipeline
        pipe = CogVideoXPipeline.from_pretrained(
            model_path,
            scheduler=scheduler,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        )
        
        # ä¼˜åŒ–å†…å­˜ä½¿ç”¨
        if device == "cuda":
            pipe.enable_model_cpu_offload()
            print("âœ… å¯ç”¨æ¨¡å‹CPUå¸è½½")
            
            # å¯ç”¨VAEåˆ‡ç‰‡ä»¥èŠ‚çœå†…å­˜
            if hasattr(pipe.vae, 'enable_slicing'):
                pipe.vae.enable_slicing()
                print("âœ… å¯ç”¨VAEåˆ‡ç‰‡")
            
            # å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡
            if hasattr(pipe, 'enable_attention_slicing'):
                pipe.enable_attention_slicing()
                print("âœ… å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡")
        else:
            pipe = pipe.to(device)

        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)

        # CogVideoX-5bæ ‡å‡†åˆ†è¾¨ç‡é…ç½®
        # æ ¹æ®æ¨¡å‹é…ç½®ï¼Œæ”¯æŒçš„åˆ†è¾¨ç‡æ˜¯åŸºäº 60x90 çš„åŸºç¡€å°ºå¯¸
        standard_resolutions = {
            "480p": (480, 720),    # åŸºç¡€åˆ†è¾¨ç‡
            "720p": (720, 1280),   # é«˜æ¸…
            "1080p": (1080, 1920), # å…¨é«˜æ¸…  
        }
        
        # é€‰æ‹©æœ€æ¥è¿‘çš„æ ‡å‡†åˆ†è¾¨ç‡
        target_ratio = width / height
        best_res = min(standard_resolutions.values(), 
                      key=lambda res: abs(res[1]/res[0] - target_ratio))
        
        final_height, final_width = best_res
        if final_height != height or final_width != width:
            print(f"âš ï¸ è°ƒæ•´è§†é¢‘å°ºå¯¸: {height}x{width} -> {final_height}x{final_width}")
            print(f"   (ä½¿ç”¨CogVideoXæ”¯æŒçš„æ ‡å‡†åˆ†è¾¨ç‡)")
        
        # ç¡®ä¿å¸§æ•°ç¬¦åˆæ¨¡å‹è¦æ±‚
        if num_frames not in [13, 25, 49]:
            adjusted_frames = min([13, 25, 49], key=lambda x: abs(x - num_frames))
            print(f"âš ï¸ è°ƒæ•´å¸§æ•°: {num_frames} -> {adjusted_frames} (æ¨¡å‹æ”¯æŒ: 13, 25, 49)")
            num_frames = adjusted_frames
        
        # ç”Ÿæˆè§†é¢‘
        print("æ­£åœ¨ç”Ÿæˆè§†é¢‘...")
        try:
            video_frames = pipe(
                prompt=prompt,
                num_videos_per_prompt=1,
                num_inference_steps=num_inference_steps,
                num_frames=num_frames,
                guidance_scale=guidance_scale,
                generator=torch.Generator(device=device).manual_seed(seed),
                height=final_height,
                width=final_width,
            ).frames[0]
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
            # å¦‚æœå‡ºé”™ï¼Œå°è¯•ä½¿ç”¨æœ€å°çš„é…ç½®
            print("ğŸ”„ å°è¯•ä½¿ç”¨æœ€å°é…ç½®é‡æ–°ç”Ÿæˆ...")
            video_frames = pipe(
                prompt=prompt,
                num_videos_per_prompt=1,
                num_inference_steps=20,  # å‡å°‘æ­¥æ•°
                num_frames=13,           # æœ€å°‘å¸§æ•°
                guidance_scale=6.0,
                generator=torch.Generator(device=device).manual_seed(seed),
                height=480,              # æœ€å°åˆ†è¾¨ç‡
                width=720,
            ).frames[0]

        # ä¿å­˜è§†é¢‘
        print("æ­£åœ¨ä¿å­˜è§†é¢‘...")
        export_to_video(video_frames, output_path, fps=8)

        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
            print(f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_path} ({file_size:.1f} MB)")
            return True
        else:
            print(f"âŒ è§†é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
            return False

    except torch.cuda.OutOfMemoryError:
        print("âŒ GPUæ˜¾å­˜ä¸è¶³ï¼")
        return False

    except Exception as e:
        print(f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    parser = argparse.ArgumentParser(description="CogVideoX-5b è§†é¢‘ç”Ÿæˆ")
    parser.add_argument("--prompt", type=str, required=True, help="è§†é¢‘æè¿°")
    parser.add_argument("--output", type=str, default="output.mp4", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--frames", type=int, default=13, help="è§†é¢‘å¸§æ•° (13, 25, 49)")
    parser.add_argument("--steps", type=int, default=50, help="æ¨ç†æ­¥æ•°")
    parser.add_argument("--height", type=int, default=480, help="è§†é¢‘é«˜åº¦")
    parser.add_argument("--width", type=int, default=720, help="è§†é¢‘å®½åº¦")
    parser.add_argument("--guidance", type=float, default=6.0, help="å¼•å¯¼å°ºåº¦")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")

    args = parser.parse_args()

    success = generate_video(
        prompt=args.prompt,
        output_path=args.output,
        num_frames=args.frames,
        num_inference_steps=args.steps,
        height=args.height,
        width=args.width,
        guidance_scale=args.guidance,
        seed=args.seed
    )

    if not success:
        print("è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
if __name__ == "__main__":
    main()
```

### 6. ä½¿ç”¨æ–¹æ³•

#### ç®€åŒ–çš„éƒ¨ç½²æµç¨‹

```bash
# ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ç¯å¢ƒï¼ˆåŒ…å«æ¨¡å‹æ£€æŸ¥ï¼‰
python check_environment.py

# ç¬¬äºŒæ­¥ï¼šæ­£å¸¸ä½¿ç”¨
python generate_video.py --prompt "ä¸€åªå¤§ç†ŠçŒ«åœ¨ç«¹æ—ä¸­åƒç«¹å­" --output "panda.mp4"
```

![éƒ¨ç½²](/images/notes/llm/Deploy-CogVideoX-5b/generate.png)

> **é‡è¦æç¤º**ï¼š`generate_video.py` è„šæœ¬å¿…é¡»æä¾› `--prompt` å‚æ•°ï¼Œè¿™æ˜¯ç”Ÿæˆè§†é¢‘çš„æ–‡æœ¬æè¿°ã€‚å¦‚æœç›´æ¥è¿è¡Œ `python generate_video.py` ä¼šæ˜¾ç¤ºå‚æ•°é”™è¯¯ã€‚

#### å‚æ•°è¯´æ˜

| å‚æ•°         | æ˜¯å¦å¿…éœ€ | é»˜è®¤å€¼     | è¯´æ˜                       | å†…å­˜å½±å“ |
| ------------ | -------- | ---------- | -------------------------- | -------- |
| `--prompt`   | **å¿…éœ€** | æ—          | è§†é¢‘æè¿°æ–‡æœ¬ï¼ˆä¸­è‹±æ–‡å‡å¯ï¼‰ | æ—        |
| `--output`   | å¯é€‰     | output.mp4 | è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„           | æ—        |
| `--frames`   | å¯é€‰     | **13**     | **è§†é¢‘å¸§æ•° (13, 25, 49)**  | **é«˜**   |
| `--steps`    | å¯é€‰     | **50**     | æ¨ç†æ­¥æ•°                   | ä¸­       |
| `--height`   | å¯é€‰     | **480**    | è§†é¢‘é«˜åº¦                   | ä¸­       |
| `--width`    | å¯é€‰     | **720**    | è§†é¢‘å®½åº¦                   | ä¸­       |
| `--guidance` | å¯é€‰     | 6.0        | å¼•å¯¼å°ºåº¦                   | ä½       |
| `--seed`     | å¯é€‰     | 42         | éšæœºç§å­                   | æ—        |

> **å†…å­˜ä¼˜åŒ–æç¤º**ï¼šé»˜è®¤å‚æ•°å·²è°ƒæ•´ä¸ºä½å†…å­˜æ¨¡å¼ï¼ˆ13 å¸§ï¼Œ480x720 åˆ†è¾¨ç‡ï¼‰ã€‚å¦‚éœ€é«˜è´¨é‡ï¼Œå¯æ‰‹åŠ¨è®¾ç½®ï¼š`--frames 49 --height 480 --width 720`ã€‚
