<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="author" content="ZhengKe"><meta http-equiv="X-UA-Compatible" content="chrome=1"><meta name="revisit-after" content="7 days"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="/favicon.svg" type="image/svg+xml"><script src="/lib/mermaid.min.js"></script><meta name="msapplication-TileColor" content="#ffffff"><meta name="theme-color" content="#ffffff"><title>中文命名实体识别(NER)项目详解</title><script>(()=>{var e=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,a=localStorage.getItem("vueuse-color-scheme")||"auto";("dark"===a||e&&"light"!==a)&&document.documentElement.classList.toggle("dark",!0)})()</script><script type="module" crossorigin="" src="/assets/app.038d67a7.js"></script><style>*,:after,:before{box-sizing:border-box;border-width:0;border-style:solid;border-color:currentColor}html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,"Apple Color Emoji","Segoe UI Emoji",Segoe UI Symbol,"Noto Color Emoji"}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}strong{font-weight:bolder}code,pre{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-size:1em}h1,h2,h3,h4,hr,p,pre{margin:0}ol,ul{list-style:none;margin:0;padding:0}img,svg{display:block;vertical-align:middle}img{max-width:100%;height:auto}:root{--c-bg:#fff;--c-scrollbar:#eee;--c-scrollbar-hover:#bbb}html{background-color:var(--c-bg)}html{overflow:scroll}*{scrollbar-color:var(--c-scrollbar) var(--c-bg)}.prose{color:var(--fg);max-width:75ch;font-size:1rem;line-height:1.75}.prose a{color:var(--fg-deeper);text-decoration:none;font-weight:500}.prose strong{color:var(--fg-deep);font-weight:600}.prose ol>li{position:relative;padding-left:1.75em}.prose ol>li:before{content:counter(list-item,var(--list-counter-style,decimal)) ".";position:absolute;font-weight:400;color:#6b7280;left:0}.prose ul>li{position:relative;padding-left:1.75em}.prose ul>li:before{content:"";position:absolute;background-color:#d1d5db;border-radius:50%;width:.375em;height:.375em;top:.6875em;left:.25em}.prose hr{border-color:#7d7d7d4d;margin-top:3em;margin-bottom:3em}.prose h1{color:var(--fg-deeper);font-weight:800;font-size:2.25em;margin-top:0;margin-bottom:.8888889em;line-height:1.1111111}.prose h2{color:var(--fg-deep);font-weight:700;font-size:1.5em;margin-top:2em;margin-bottom:1em;line-height:1.3333333}.prose h3{color:inherit;font-weight:600;font-size:1.25em;margin-top:1.6em;margin-bottom:.6em;line-height:1.6}.prose h4{color:inherit;font-weight:600;margin-top:1.5em;margin-bottom:.5em;line-height:1.5}.prose code{color:var(--fg-deep);font-weight:600;font-size:.875em}.prose code:before{content:"`"}.prose code:after{content:"`"}.prose pre{color:#e5e7eb;background-color:#1f2937;overflow-x:auto;font-size:.875em;line-height:1.7142857;margin-top:1.7142857em;margin-bottom:1.7142857em;border-radius:.375rem;padding:.8571429em 1.1428571em}.prose pre code{background-color:transparent;border-width:0;border-radius:0;padding:0;font-weight:400;color:inherit;font-size:inherit;font-family:inherit;line-height:inherit}.prose pre code:before{content:none}.prose pre code:after{content:none}.prose p{margin-top:1.25em;margin-bottom:1.25em}.prose ol,.prose ul{margin-top:1.25em;margin-bottom:1.25em;list-style-type:none}.prose li{margin-top:.5em;margin-bottom:.5em}.prose>ol>li>:first-child{margin-top:1.25em}.prose>ol>li>:last-child{margin-bottom:1.25em}.prose>:first-child{margin-top:0}.prose>:last-child{margin-bottom:0}:root{--prism-scheme:light;--prism-foreground:#6e6e6e;--prism-background:#f4f4f4;--prism-comment:#a8a8a8;--prism-string:#555555;--prism-literal:#333333;--prism-keyword:#000000;--prism-function:#4f4f4f;--prism-deleted:#333333;--prism-class:#333333;--prism-builtin:#757575;--prism-property:#333333;--prism-namespace:#4f4f4f;--prism-punctuation:#ababab;--prism-decorator:var(--prism-class);--prism-operator:var(--prism-punctuation);--prism-number:var(--prism-literal);--prism-boolean:var(--prism-literal);--prism-variable:var(--prism-literal);--prism-constant:var(--prism-literal);--prism-symbol:var(--prism-literal);--prism-interpolation:var(--prism-literal);--prism-selector:var(--prism-keyword);--prism-keyword-control:var(--prism-keyword);--prism-regex:var(--prism-string);--prism-json-property:var(--prism-property);--prism-inline-background:var(--prism-background);--prism-comment-style:italic;--prism-url-decoration:underline;--prism-line-number:#a5a5a5;--prism-line-number-gutter:#333333;--prism-line-highlight-background:#eeeeee;--prism-selection-background:#dddddd;--prism-marker-color:var(--prism-foreground);--prism-marker-opacity:.4;--prism-marker-font-size:.8em;--prism-font-size:1em;--prism-line-height:1.5em;--prism-font-family:monospace;--prism-inline-font-size:var(--prism-font-size);--prism-block-font-size:var(--prism-font-size);--prism-tab-size:2;--prism-block-padding-x:1em;--prism-block-padding-y:1em;--prism-block-margin-x:0;--prism-block-margin-y:.5em;--prism-block-radius:.3em;--prism-inline-padding-x:.3em;--prism-inline-padding-y:.1em;--prism-inline-radius:.3em}code[class*=language-],pre[class*=language-]{font-size:var(--prism-font-size);font-family:var(--prism-font-family);direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:var(--prism-line-height);-moz-tab-size:var(--prism-tab-size);-o-tab-size:var(--prism-tab-size);tab-size:var(--prism-tab-size);-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;color:var(--prism-foreground)!important}pre[class*=language-]{font-size:var(--prism-block-font-size);padding:var(--prism-block-padding-y) var(--prism-block-padding-x);margin:var(--prism-block-margin-y) var(--prism-block-margin-x);border-radius:var(--prism-block-radius);overflow:auto;background:var(--prism-background)}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{background:var(--prism-selection-background)}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:var(--prism-selection-background)}.token.comment{color:var(--prism-comment);font-style:var(--prism-comment-style)}.token.interpolation{color:var(--prism-interpolation)}.token.string{color:var(--prism-string)}.token.punctuation{color:var(--prism-punctuation)}.token.operator{color:var(--prism-operator)}.token.boolean{color:var(--prism-boolean)}.language-json .token.number,.token.number{color:var(--prism-number)}.token.keyword{color:var(--prism-keyword)}.token.function{color:var(--prism-function)}.token.builtin{color:var(--prism-builtin)}.token.property{color:var(--prism-property)}.language-json .token.property{color:var(--prism-json-property)}:root{--prism-font-size:.9rem;--prism-font-family:"Fira Code",monospace}:root{--prism-font-family:"Input Mono",monospace}html:not(.dark){--prism-foreground:#393a34;--prism-background:#fbfbfb;--prism-comment:#a0ada0;--prism-string:#b56959;--prism-literal:#2f8a89;--prism-number:#296aa3;--prism-keyword:#1c6b48;--prism-function:#6c7834;--prism-boolean:#1c6b48;--prism-constant:#a65e2b;--prism-deleted:#a14f55;--prism-class:#2993a3;--prism-builtin:#ab5959;--prism-property:#b58451;--prism-namespace:#b05a78;--prism-punctuation:#8e8f8b;--prism-decorator:#bd8f8f;--prism-regex:#ab5e3f;--prism-json-property:#698c96}.prose{--fg:#555;--fg-deep:#222;--fg-deeper:#000;color:var(--fg)}.prose a{font-weight:inherit;text-decoration:none;border-bottom:1px solid rgba(125,125,125,.3);transition:border .3s ease-in-out}.prose a:hover{border-bottom:1px solid var(--fg)}.prose hr{width:50px;margin:2em auto}a.header-anchor{float:left;margin-top:.125em;margin-left:-1.2em;padding-right:.5em;font-size:.85em;opacity:0;text-decoration:none;border:0!important}a.header-anchor:focus,a.header-anchor:hover{text-decoration:none}h2:focus .header-anchor,h2:hover .header-anchor,h3:focus .header-anchor,h3:hover .header-anchor,h4:focus .header-anchor,h4:hover .header-anchor{opacity:.5}.absolute{position:absolute}.z-40{z-index:40}.m-6{margin:1.5rem}.m-auto{margin:auto}.\!-mt-2{margin-top:-.5rem!important}.mb-0{margin-bottom:0}.mb-6{margin-bottom:1.5rem}.mb-8{margin-bottom:2rem}.mt-10{margin-top:2.5rem}.mt-8{margin-top:2rem}.h-10{height:2.5rem}.w-10{width:2.5rem}.flex{display:flex}.flex-auto{flex:1 1 auto}.select-none{user-select:none}.px-7{padding-left:1.75rem;padding-right:1.75rem}.py-10{padding-top:2.5rem;padding-bottom:2.5rem}.font-mono{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}.font-sans{font-family:Inter,Inter var,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}.text-sm{font-size:.875rem;line-height:1.25rem}.text-gray-700{--un-text-opacity:1;color:rgba(55,65,81,var(--un-text-opacity))}.no-underline{text-decoration:none}.opacity-50{opacity:.5}.hover\:opacity-75:hover{opacity:.75}.outline-none{outline:2px solid transparent;outline-offset:2px}@media (max-width:768px){.lt-md\:hidden{display:none}}@media (min-width:768px){.md\:hidden{display:none}}@media (min-width:1024px){.lg\:fixed{position:fixed}}.nav[data-v-568133b8]{padding:2rem;width:100%;display:grid;grid-template-columns:auto max-content;box-sizing:border-box}.nav[data-v-568133b8]>*{margin:auto}.nav a[data-v-568133b8]{cursor:pointer;text-decoration:none;color:inherit;transition:opacity .2s ease;opacity:.6;outline:0}.nav a[data-v-568133b8]:hover{opacity:1;text-decoration-color:inherit}.nav .right[data-v-568133b8]{display:grid;grid-gap:1.2rem;grid-auto-flow:column}.nav .right[data-v-568133b8]>*{margin:auto}.mathjax-container[data-v-011ba505]{color:inherit;font-family:inherit;line-height:inherit}</style><link rel="preload" href="/assets/app.baf61519.css" as="style"><link rel="modulepreload" crossorigin="" href="/assets/python-ner.8bf180a3.js"><link rel="modulepreload" crossorigin="" href="/assets/Post.dd5dd46a.js"><link rel="preload" href="/assets/Post.63afffbd.css" as="style"><meta property="og:title" content="中文命名实体识别(NER)项目详解"><meta name="head:count" content="1"></head><body class="font-sans text-gray-700 dark:text-gray-200"><div id="app" data-server-rendered="true"><!--[--><header class="header z-40" data-v-568133b8=""><a href="/" class="w-10 h-10 absolute lg:fixed m-6 select-none outline-none" focusable="false" data-v-568133b8=""><img src="/logo-dark.svg" alt="logo" style="display:none" data-v-568133b8=""><img src="/logo.svg" alt="logo" data-v-568133b8=""></a><nav class="nav" data-v-568133b8=""><div class="spacer" data-v-568133b8=""></div><div class="right" data-v-568133b8=""><a href="/posts" class="" data-v-568133b8=""><span class="lt-md:hidden" data-v-568133b8="">Blog</span><svg style="vertical-align:sub" class="inline md:hidden" width="1.2em" height="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24" data-v-568133b8=""><path fill="currentColor" d="M20 22H4a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h16a1 1 0 0 1 1 1v18a1 1 0 0 1-1 1m-1-2V4H5v16zM7 6h4v4H7zm0 6h10v2H7zm0 4h10v2H7zm6-9h4v2h-4z"></path></svg></a><a href="/llm" class="lt-md:hidden" data-v-568133b8="">LLM </a><a href="/notes" class="" title="Notes" data-v-568133b8=""><span class="lt-md:hidden" data-v-568133b8="">Notes</span><svg style="vertical-align:sub" class="inline md:hidden" width="1.2em" height="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24" data-v-568133b8=""><path fill="currentColor" d="m17.85 11.698l-.708-.707l-9.9 9.9H3v-4.243L14.314 5.334l5.657 5.657a1 1 0 0 1 0 1.414L12.9 19.477l-1.415-1.415zm-2.122-2.121l-1.414-1.414L5 17.477v1.414h1.414zm2.828-7.071l2.829 2.828a1 1 0 0 1 0 1.415L19.97 8.163L15.728 3.92l1.414-1.414a1 1 0 0 1 1.414 0"></path></svg></a><a href="https://github.com/ZhengKe0110" target="_blank" title="GitHub" class="lt-md:hidden" data-v-568133b8=""><svg style="vertical-align:sub" class="inline" width="1.2em" height="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24" data-v-568133b8=""><path fill="currentColor" d="M10.07 20.503a1 1 0 0 0-1.18-.983c-1.31.24-2.963.276-3.402-.958a5.7 5.7 0 0 0-1.837-2.415a1 1 0 0 1-.167-.11a1 1 0 0 0-.93-.645h-.005a1 1 0 0 0-1 .995c-.004.815.81 1.338 1.141 1.514a4.4 4.4 0 0 1 .924 1.36c.365 1.023 1.423 2.576 4.466 2.376l.003.098l.004.268a1 1 0 0 0 2 0l-.005-.318c-.005-.19-.012-.464-.012-1.182M20.737 5.377q.049-.187.09-.42a6.3 6.3 0 0 0-.408-3.293a1 1 0 0 0-.615-.58c-.356-.12-1.67-.357-4.184 1.25a13.9 13.9 0 0 0-6.354 0C6.762.75 5.455.966 5.102 1.079a1 1 0 0 0-.631.584a6.3 6.3 0 0 0-.404 3.357q.037.191.079.354a6.27 6.27 0 0 0-1.256 3.83a8 8 0 0 0 .043.921c.334 4.603 3.334 5.984 5.424 6.459a5 5 0 0 0-.118.4a1 1 0 0 0 1.942.479a1.7 1.7 0 0 1 .468-.878a1 1 0 0 0-.546-1.745c-3.454-.395-4.954-1.802-5.18-4.899a7 7 0 0 1-.033-.738a4.26 4.26 0 0 1 .92-2.713a3 3 0 0 1 .195-.231a1 1 0 0 0 .188-1.025a3.4 3.4 0 0 1-.155-.555a4.1 4.1 0 0 1 .079-1.616a7.5 7.5 0 0 1 2.415 1.18a1 1 0 0 0 .827.133a11.8 11.8 0 0 1 6.173.001a1 1 0 0 0 .83-.138a7.6 7.6 0 0 1 2.406-1.19a4 4 0 0 1 .087 1.578a3.2 3.2 0 0 1-.169.607a1 1 0 0 0 .188 1.025c.078.087.155.18.224.268A4.12 4.12 0 0 1 20 9.203a7 7 0 0 1-.038.777c-.22 3.056-1.725 4.464-5.195 4.86a1 1 0 0 0-.546 1.746a1.63 1.63 0 0 1 .466.908a3 3 0 0 1 .093.82v2.333c-.01.648-.01 1.133-.01 1.356a1 1 0 1 0 2 0c0-.217 0-.692.01-1.34v-2.35a5 5 0 0 0-.155-1.311a4 4 0 0 0-.116-.416a6.51 6.51 0 0 0 5.445-6.424A9 9 0 0 0 22 9.203a6.13 6.13 0 0 0-1.263-3.826"></path></svg></a><a class="select-none" title="Toggle Color Scheme" data-v-568133b8=""><svg style="vertical-align:sub;display:none" class="inline" width="1.2em" height="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path fill="currentColor" d="M10 7a7 7 0 0 0 12 4.9v.1c0 5.523-4.477 10-10 10S2 17.523 2 12S6.477 2 12 2h.1A6.98 6.98 0 0 0 10 7m-6 5a8 8 0 0 0 15.062 3.762A9 9 0 0 1 8.238 4.938A8 8 0 0 0 4 12"></path></svg><svg style="vertical-align:sub" class="inline" width="1.2em" height="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path fill="currentColor" d="M12 18a6 6 0 1 1 0-12a6 6 0 0 1 0 12m0-2a4 4 0 1 0 0-8a4 4 0 0 0 0 8M11 1h2v3h-2zm0 19h2v3h-2zM3.515 4.929l1.414-1.414L7.05 5.636L5.636 7.05zM16.95 18.364l1.414-1.414l2.121 2.121l-1.414 1.414zm2.121-14.85l1.414 1.415l-2.121 2.121l-1.414-1.414zM5.636 16.95l1.414 1.414l-2.121 2.121l-1.414-1.414zM23 11v2h-3v-2zM4 11v2H1v-2z"></path></svg></a></div></nav></header><main class="px-7 py-10"><!--[--><div class="prose m-auto mb-8"><h1 class="mb-0">中文命名实体识别(NER)项目详解</h1><p class="opacity-50 !-mt-2">Jul 16<!----></p><!----></div><article><div class="mathjax-container" data-v-011ba505=""><!--[--><!--[--><div class="prose m-auto"><p>Link: <a href="https://github.com/Zhengke0110/NER" target="_blank" rel="noopener">https://github.com/Zhengke0110/NER</a></p><h2 id="项目概述" tabindex="-1">项目概述 <a class="header-anchor" href="#项目概述" aria-hidden="true">#</a></h2><p>NER 项目是一个基于 BERT 的中文命名实体识别系统，主要用于识别文本中的实体类型。项目采用 BIO 标注体系，使用 <code>transformers</code> 库进行模型训练和预测。</p><hr><h2 id="数据预处理流程" tabindex="-1">数据预处理流程 <a class="header-anchor" href="#数据预处理流程" aria-hidden="true">#</a></h2><h3 id="预处理流程图" tabindex="-1">预处理流程图 <a class="header-anchor" href="#预处理流程图" aria-hidden="true">#</a></h3><pre class="language-mermaid"><code class="language-mermaid"><span class="token keyword">graph</span> TD
    A<span class="token text string">[原始JSON标注数据&lt;br/&gt;admin.jsonl]</span> <span class="token arrow operator">--&gt;</span> B<span class="token text string">[数据格式转换&lt;br/&gt;DataConvert.py]</span>
    B <span class="token arrow operator">--&gt;</span> C<span class="token text string">[JSON转BIO格式&lt;br/&gt;convert.py]</span>
    C <span class="token arrow operator">--&gt;</span> D<span class="token text string">[分词处理&lt;br/&gt;get_token函数]</span>
    D <span class="token arrow operator">--&gt;</span> E<span class="token text string">[实体标注映射&lt;br/&gt;BIO标签生成]</span>
    E <span class="token arrow operator">--&gt;</span> F<span class="token text string">[输出BIO格式文件&lt;br/&gt;train_BIO.txt]</span>

    F <span class="token arrow operator">--&gt;</span> G<span class="token text string">[数据读取&lt;br/&gt;dataUtils.py]</span>
    G <span class="token arrow operator">--&gt;</span> H<span class="token text string">[标签映射创建&lt;br/&gt;create_label_mappings]</span>
    H <span class="token arrow operator">--&gt;</span> I<span class="token text string">[数据编码&lt;br/&gt;BERT Tokenizer]</span>
    I <span class="token arrow operator">--&gt;</span> J<span class="token text string">[数据集构建&lt;br/&gt;NERDataset]</span>

    <span class="token keyword">style</span> A <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FF6B6B<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> B <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#4ECDC4<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> C <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FFD93D<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#333</span>
    <span class="token keyword">style</span> D <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#6BCF7F<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> E <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#4D96FF<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> F <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#9B59B6<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> G <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FF8C42<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> H <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#3498DB<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> I <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#E74C3C<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> J <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#1ABC9C<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
</code></pre><h3 id="数据转换核心代码" tabindex="-1">数据转换核心代码 <a class="header-anchor" href="#数据转换核心代码" aria-hidden="true">#</a></h3><h4 id="分词处理函数" tabindex="-1">分词处理函数 <a class="header-anchor" href="#分词处理函数" aria-hidden="true">#</a></h4><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_token</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    将文本分词，英文字母作为单词处理，其他字符单独处理

    Args:
        text: 输入文本

    Returns:
        分词后的列表
    """</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> text<span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"输入文本不能为空"</span><span class="token punctuation">)</span>

    english_letters <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token string">'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>

    <span class="token keyword">for</span> char <span class="token keyword">in</span> text<span class="token punctuation">:</span>
        <span class="token keyword">if</span> char <span class="token keyword">in</span> english_letters<span class="token punctuation">:</span>
            <span class="token builtin">buffer</span> <span class="token operator">+=</span> char
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>
                output<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
                <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>
            <span class="token keyword">if</span> char<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 忽略空白字符</span>
                output<span class="token punctuation">.</span>append<span class="token punctuation">(</span>char<span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>
        output<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> output
</code></pre><p><strong>功能说明</strong>:</p><ul><li>智能分词处理，将英文字母组合为单词，中文字符单独处理</li><li>过滤空白字符，保证分词结果的质量</li><li>为后续的 BIO 标注提供合适的 token 粒度</li></ul><h4 id="json-到-bio-转换核心函数" tabindex="-1">JSON 到 BIO 转换核心函数 <a class="header-anchor" href="#json-到-bio-转换核心函数" aria-hidden="true">#</a></h4><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">json2bio</span><span class="token punctuation">(</span>input_file<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> output_file<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> split_by<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">'s'</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    将JSON格式的标注数据转换为BIO格式

    Args:
        input_file: 输入JSON文件路径
        output_file: 输出BIO格式文件路径
        split_by: 分割方式（暂未使用）
    """</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>input_file<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_in<span class="token punctuation">,</span> \
             <span class="token builtin">open</span><span class="token punctuation">(</span>output_file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_out<span class="token punctuation">:</span>

            <span class="token keyword">for</span> line_num<span class="token punctuation">,</span> line <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>f_in<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># 1. 解析JSON数据</span>
                annotations <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                <span class="token comment"># 2. 验证必要字段（text和label）</span>
                <span class="token comment"># 3. 预处理文本（移除换行符等）</span>
                text <span class="token operator">=</span> annotations<span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>

                <span class="token comment"># 4. 使用get_token函数进行分词</span>
                tokens <span class="token operator">=</span> get_token<span class="token punctuation">(</span>text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> <span class="token string">','</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                <span class="token comment"># 5. 初始化所有标签为'O'</span>
                labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'O'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>

                <span class="token comment"># 6. 处理实体标注</span>
                <span class="token keyword">for</span> entity <span class="token keyword">in</span> annotations<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                    start_pos<span class="token punctuation">,</span> end_pos<span class="token punctuation">,</span> entity_type <span class="token operator">=</span> entity<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> entity<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> entity<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>

                    <span class="token comment"># 设置BIO标签：B-开头，I-内部</span>
                    labels<span class="token punctuation">[</span>start_pos<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'B-</span><span class="token interpolation"><span class="token punctuation">{</span>entity_type<span class="token punctuation">}</span></span><span class="token string">'</span></span>
                    <span class="token keyword">for</span> pos <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_pos <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> end_pos<span class="token punctuation">)</span><span class="token punctuation">:</span>
                        labels<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'I-</span><span class="token interpolation"><span class="token punctuation">{</span>entity_type<span class="token punctuation">}</span></span><span class="token string">'</span></span>

                <span class="token comment"># 7. 写入BIO格式文件</span>
                <span class="token keyword">for</span> token<span class="token punctuation">,</span> label <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    f_out<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>token<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>label<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>
                f_out<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>  <span class="token comment"># 句子间空行分隔</span>

    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"转换过程中发生错误: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># 转换流程伪代码:</span>
<span class="token comment"># FOR 每一行JSON数据:</span>
<span class="token comment">#   1. 解析JSON → 获取text和label字段</span>
<span class="token comment">#   2. 数据验证 → 检查必要字段是否存在</span>
<span class="token comment">#   3. 文本预处理 → 清理换行符和特殊字符</span>
<span class="token comment">#   4. 智能分词 → 调用get_token函数</span>
<span class="token comment">#   5. 标签初始化 → 所有token默认标记为'O'</span>
<span class="token comment">#   6. 实体标注 → 根据位置信息设置B-/I-标签</span>
<span class="token comment">#   7. 格式输出 → 写入"token label"格式</span>
<span class="token comment">#   8. 错误处理 → 记录异常并继续处理</span>
</code></pre><p><strong>功能说明</strong>:</p><ul><li><strong>核心转换逻辑</strong>: 将 JSON 中的位置标注转换为 BIO 标注体系</li><li><strong>标注规则</strong>: B-标签表示实体开始，I-标签表示实体内部，O 表示非实体</li><li><strong>容错处理</strong>: 对格式错误和边界异常进行验证和处理</li><li><strong>输出格式</strong>: 每行一个 token 及其对应标签，句子间用空行分隔</li></ul><h3 id="数据格式示例" tabindex="-1">数据格式示例 <a class="header-anchor" href="#数据格式示例" aria-hidden="true">#</a></h3><h4 id="原始-json-格式" tabindex="-1">原始 JSON 格式: <a class="header-anchor" href="#原始-json-格式" aria-hidden="true">#</a></h4><pre class="language-json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"id"</span><span class="token operator">:</span> <span class="token number">41</span><span class="token punctuation">,</span>
  <span class="token property">"text"</span><span class="token operator">:</span> <span class="token string">"词汇阅读是关键 08年考研暑期英语复习全指南"</span><span class="token punctuation">,</span>
  <span class="token property">"label"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token string">"year"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token string">"exam"</span><span class="token punctuation">]</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token property">"Comments"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre><h4 id="转换后的-bio-格式" tabindex="-1">转换后的 BIO 格式: <a class="header-anchor" href="#转换后的-bio-格式" aria-hidden="true">#</a></h4><pre><code>词 O
汇 O
阅 O
读 O
是 O
关 O
键 O
, O
0 B-year
8 I-year
年 I-year
考 B-exam
研 I-exam
暑 I-exam
期 I-exam
英 I-exam
语 I-exam
复 O
习 O
</code></pre><h3 id="数据处理" tabindex="-1">数据处理 <a class="header-anchor" href="#数据处理" aria-hidden="true">#</a></h3><h4 id="标签映射创建" tabindex="-1">标签映射创建 <a class="header-anchor" href="#标签映射创建" aria-hidden="true">#</a></h4><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">create_label_mappings</span><span class="token punctuation">(</span>train_tags<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tuple<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Dict<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    创建标签映射

    Returns:
        tuple: (tag2id, id2tag, label_list)
    """</span>
    <span class="token comment"># 收集所有唯一标签</span>
    unique_tags <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> doc_tags <span class="token keyword">in</span> train_tags<span class="token punctuation">:</span>
        unique_tags<span class="token punctuation">.</span>update<span class="token punctuation">(</span>doc_tags<span class="token punctuation">)</span>

    <span class="token comment"># 创建映射</span>
    unique_tags <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>unique_tags<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 保证顺序一致</span>
    tag2id <span class="token operator">=</span> <span class="token punctuation">{</span>tag<span class="token punctuation">:</span> <span class="token builtin">id</span> <span class="token keyword">for</span> <span class="token builtin">id</span><span class="token punctuation">,</span> tag <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>unique_tags<span class="token punctuation">)</span><span class="token punctuation">}</span>
    id2tag <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token builtin">id</span><span class="token punctuation">:</span> tag <span class="token keyword">for</span> tag<span class="token punctuation">,</span> <span class="token builtin">id</span> <span class="token keyword">in</span> tag2id<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    label_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>unique_tags<span class="token punctuation">)</span>

    <span class="token keyword">return</span> tag2id<span class="token punctuation">,</span> id2tag<span class="token punctuation">,</span> label_list
</code></pre><p><strong>功能说明</strong>:</p><ul><li>从训练数据中提取所有唯一的标签</li><li>创建标签到 ID 的双向映射</li><li>为模型训练提供标签字典</li></ul><hr><h2 id="模型训练流程" tabindex="-1">模型训练流程 <a class="header-anchor" href="#模型训练流程" aria-hidden="true">#</a></h2><h3 id="训练流程图" tabindex="-1">训练流程图 <a class="header-anchor" href="#训练流程图" aria-hidden="true">#</a></h3><pre class="language-mermaid"><code class="language-mermaid"><span class="token keyword">graph</span> TD
    A<span class="token text string">[配置文件加载&lt;br/&gt;config.json]</span> <span class="token arrow operator">--&gt;</span> B<span class="token text string">[数据集准备&lt;br/&gt;prepare_datasets]</span>
    B <span class="token arrow operator">--&gt;</span> C<span class="token text string">[BERT Tokenizer&lt;br/&gt;创建分词器]</span>
    C <span class="token arrow operator">--&gt;</span> D<span class="token text string">[数据编码&lt;br/&gt;encode_tags]</span>
    D <span class="token arrow operator">--&gt;</span> E<span class="token text string">[数据集构建&lt;br/&gt;NERDataset]</span>

    E <span class="token arrow operator">--&gt;</span> F<span class="token text string">[模型创建&lt;br/&gt;AutoModelForTokenClassification]</span>
    F <span class="token arrow operator">--&gt;</span> G<span class="token text string">[评估函数创建&lt;br/&gt;create_compute_metrics_fn]</span>
    G <span class="token arrow operator">--&gt;</span> H<span class="token text string">[训练参数设置&lt;br/&gt;TrainingArguments]</span>
    H <span class="token arrow operator">--&gt;</span> I<span class="token text string">[Trainer创建&lt;br/&gt;create_trainer]</span>

    I <span class="token arrow operator">--&gt;</span> J<span class="token text string">[模型训练&lt;br/&gt;trainer.train]</span>
    J <span class="token arrow operator">--&gt;</span> K<span class="token text string">[模型保存&lt;br/&gt;save_model]</span>
    K <span class="token arrow operator">--&gt;</span> L<span class="token text string">[训练完成&lt;br/&gt;输出结果]</span>

    <span class="token keyword">style</span> A <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FF6B6B<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> B <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#4ECDC4<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> C <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FFD93D<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#333</span>
    <span class="token keyword">style</span> D <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#6BCF7F<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> E <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#4D96FF<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> F <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#9B59B6<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> G <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FF8C42<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> H <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#3498DB<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> I <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#E74C3C<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> J <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#1ABC9C<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>4px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> K <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#F39C12<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> L <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#8E44AD<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
</code></pre><h3 id="训练核心代码" tabindex="-1">训练核心代码 <a class="header-anchor" href="#训练核心代码" aria-hidden="true">#</a></h3><h4 id="模型创建函数" tabindex="-1">模型创建函数 <a class="header-anchor" href="#模型创建函数" aria-hidden="true">#</a></h4><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">create_model</span><span class="token punctuation">(</span>
    model_config<span class="token punctuation">,</span> tag2id<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> id2tag<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> AutoModelForTokenClassification<span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    创建NER模型

    Args:
        model_config: 模型配置
        tag2id: 标签到ID的映射
        id2tag: ID到标签的映射

    Returns:
        初始化的模型
    """</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"正在创建模型: </span><span class="token interpolation"><span class="token punctuation">{</span>model_config<span class="token punctuation">.</span>model_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"标签数量: </span><span class="token interpolation"><span class="token punctuation">{</span>model_config<span class="token punctuation">.</span>num_labels<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

        model <span class="token operator">=</span> AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            model_config<span class="token punctuation">.</span>model_name<span class="token punctuation">,</span>
            num_labels<span class="token operator">=</span>model_config<span class="token punctuation">.</span>num_labels<span class="token punctuation">,</span>
            id2label<span class="token operator">=</span>id2tag<span class="token punctuation">,</span>
            label2id<span class="token operator">=</span>tag2id<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"模型创建成功"</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> model

    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"创建模型失败: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">raise</span>
</code></pre><p><strong>功能说明</strong>:</p><ul><li>基于预训练的 BERT-base-chinese 模型创建 token 分类模型</li><li>自动设置标签数量和标签映射关系</li><li>利用 Hugging Face transformers 库的自动模型配置</li></ul><h4 id="数据编码核心函数" tabindex="-1">数据编码核心函数 <a class="header-anchor" href="#数据编码核心函数" aria-hidden="true">#</a></h4><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">encode_tags</span><span class="token punctuation">(</span>tags<span class="token punctuation">,</span> encodings<span class="token punctuation">,</span> tag2id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    标签编码函数

    Args:
        tags: 原始标签列表，每个元素是一个文档的标签列表
        encodings: tokenizer编码结果
        tag2id: 标签到ID的映射

    Returns:
        编码后的标签列表
    """</span>
    <span class="token comment"># 将标签转换为ID</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>tag2id<span class="token punctuation">[</span>tag<span class="token punctuation">]</span> <span class="token keyword">for</span> tag <span class="token keyword">in</span> doc<span class="token punctuation">]</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> tags<span class="token punctuation">]</span>

    encoded_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> doc_labels<span class="token punctuation">,</span> doc_offset <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>labels<span class="token punctuation">,</span> encodings<span class="token punctuation">.</span>offset_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 创建全由-100组成的数组（用于忽略loss计算）</span>
        doc_enc_labels <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>doc_offset<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">100</span>

        <span class="token comment"># 追踪当前处理到的原始token位置</span>
        token_idx <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>doc_offset<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 跳过特殊token：[CLS], [SEP], [PAD]等</span>
            <span class="token keyword">if</span> start <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> end <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>

            <span class="token comment"># 只为每个原始token的第一个subword分配标签</span>
            <span class="token keyword">if</span> start <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> end <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> token_idx <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>doc_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    doc_enc_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> doc_labels<span class="token punctuation">[</span>token_idx<span class="token punctuation">]</span>
                    token_idx <span class="token operator">+=</span> <span class="token number">1</span>

        encoded_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>doc_enc_labels<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> encoded_labels
</code></pre><p><strong>功能说明</strong>:</p><ul><li>处理 BERT tokenizer 的子词分割问题</li><li>将原始 BIO 标签映射到 tokenizer 产生的子词上</li><li>使用-100 标记填充位置和特殊 token，在计算 loss 时会被忽略</li></ul><h4 id="训练参数配置" tabindex="-1">训练参数配置 <a class="header-anchor" href="#训练参数配置" aria-hidden="true">#</a></h4><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">create_training_arguments</span><span class="token punctuation">(</span>training_config<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> TrainingArguments<span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    创建训练参数

    Args:
        training_config: 训练配置

    Returns:
        训练参数对象
    """</span>
    training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
        output_dir<span class="token operator">=</span>training_config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span>  <span class="token comment"># 输出目录</span>
        num_train_epochs<span class="token operator">=</span>training_config<span class="token punctuation">.</span>num_train_epochs<span class="token punctuation">,</span>  <span class="token comment"># 训练轮数</span>
        per_device_train_batch_size<span class="token operator">=</span>training_config<span class="token punctuation">.</span>per_device_train_batch_size<span class="token punctuation">,</span>  <span class="token comment"># 训练批次大小</span>
        per_device_eval_batch_size<span class="token operator">=</span>training_config<span class="token punctuation">.</span>per_device_eval_batch_size<span class="token punctuation">,</span>  <span class="token comment"># 评估批次大小</span>
        learning_rate<span class="token operator">=</span>training_config<span class="token punctuation">.</span>learning_rate<span class="token punctuation">,</span>  <span class="token comment"># 学习率</span>
        warmup_steps<span class="token operator">=</span>training_config<span class="token punctuation">.</span>warmup_steps<span class="token punctuation">,</span>  <span class="token comment"># 预热步数</span>
        weight_decay<span class="token operator">=</span>training_config<span class="token punctuation">.</span>weight_decay<span class="token punctuation">,</span>  <span class="token comment"># 权重衰减</span>
        logging_dir<span class="token operator">=</span>training_config<span class="token punctuation">.</span>logging_dir<span class="token punctuation">,</span>  <span class="token comment"># 日志目录</span>
        logging_steps<span class="token operator">=</span>training_config<span class="token punctuation">.</span>logging_steps<span class="token punctuation">,</span>  <span class="token comment"># 日志步数</span>
        save_strategy<span class="token operator">=</span>training_config<span class="token punctuation">.</span>save_strategy<span class="token punctuation">,</span>  <span class="token comment"># 保存策略</span>
        save_steps<span class="token operator">=</span>training_config<span class="token punctuation">.</span>save_steps<span class="token punctuation">,</span>
        save_total_limit<span class="token operator">=</span>training_config<span class="token punctuation">.</span>save_total_limit<span class="token punctuation">,</span>  <span class="token comment"># 保存数量限制</span>
        eval_strategy<span class="token operator">=</span>training_config<span class="token punctuation">.</span>eval_strategy<span class="token punctuation">,</span>  <span class="token comment"># 评估策略</span>
        eval_steps<span class="token operator">=</span>training_config<span class="token punctuation">.</span>eval_steps<span class="token punctuation">,</span>  <span class="token comment"># 评估步数</span>
        load_best_model_at_end<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 加载最佳模型</span>
        metric_for_best_model<span class="token operator">=</span><span class="token string">"f1"</span><span class="token punctuation">,</span>  <span class="token comment"># 评估指标</span>
        greater_is_better<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 评估指标是否越</span>
        report_to<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 禁用wandb等日志记录</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">return</span> training_args
</code></pre><p><strong>功能说明</strong>:</p><ul><li>配置训练的各项超参数，包括学习率、批次大小、训练轮数等</li><li>设置保存策略和评估策略</li><li>使用 F1 分数作为最佳模型选择标准</li></ul><h3 id="训练配置示例" tabindex="-1">训练配置示例 <a class="header-anchor" href="#训练配置示例" aria-hidden="true">#</a></h3><h4 id="config-json-训练配置部分" tabindex="-1">config.json 训练配置部分: <a class="header-anchor" href="#config-json-训练配置部分" aria-hidden="true">#</a></h4><pre class="language-json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"training"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"output_dir"</span><span class="token operator">:</span> <span class="token string">"./output"</span><span class="token punctuation">,</span>
    <span class="token property">"num_train_epochs"</span><span class="token operator">:</span> <span class="token number">1000</span><span class="token punctuation">,</span>
    <span class="token property">"per_device_train_batch_size"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
    <span class="token property">"per_device_eval_batch_size"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
    <span class="token property">"learning_rate"</span><span class="token operator">:</span> <span class="token number">5e-5</span><span class="token punctuation">,</span>
    <span class="token property">"warmup_steps"</span><span class="token operator">:</span> <span class="token number">500</span><span class="token punctuation">,</span>
    <span class="token property">"weight_decay"</span><span class="token operator">:</span> <span class="token number">0.01</span><span class="token punctuation">,</span>
    <span class="token property">"logging_steps"</span><span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
    <span class="token property">"save_strategy"</span><span class="token operator">:</span> <span class="token string">"steps"</span><span class="token punctuation">,</span>
    <span class="token property">"save_steps"</span><span class="token operator">:</span> <span class="token number">1000</span><span class="token punctuation">,</span>
    <span class="token property">"eval_strategy"</span><span class="token operator">:</span> <span class="token string">"steps"</span><span class="token punctuation">,</span>
    <span class="token property">"eval_steps"</span><span class="token operator">:</span> <span class="token number">1000</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><h3 id="训练流程总结" tabindex="-1">训练流程总结 <a class="header-anchor" href="#训练流程总结" aria-hidden="true">#</a></h3><p>模型训练阶段完成了以下关键任务：</p><ol><li><strong>模型初始化</strong>: 基于 BERT-base-chinese 创建 token 分类模型</li><li><strong>数据编码</strong>: 处理子词分割和标签对齐问题</li><li><strong>评估设置</strong>: 配置实体级别的评估指标</li><li><strong>参数优化</strong>: 设置学习率调度和权重衰减</li><li><strong>模型保存</strong>: 自动保存最佳性能的模型检查点</li></ol><p>训练过程通过模块化设计实现了高效的端到端训练流程，确保了模型的性能和稳定性。</p><hr><h2 id="模型验证流程" tabindex="-1">模型验证流程 <a class="header-anchor" href="#模型验证流程" aria-hidden="true">#</a></h2><h3 id="验证流程图" tabindex="-1">验证流程图 <a class="header-anchor" href="#验证流程图" aria-hidden="true">#</a></h3><pre class="language-mermaid"><code class="language-mermaid"><span class="token keyword">graph</span> TD
    A<span class="token text string">[训练完成的模型&lt;br/&gt;checkpoint/model/]</span> <span class="token arrow operator">--&gt;</span> B<span class="token text string">[模型加载&lt;br/&gt;AutoModelForTokenClassification]</span>
    B <span class="token arrow operator">--&gt;</span> C<span class="token text string">[Tokenizer加载&lt;br/&gt;BertTokenizerFast]</span>
    C <span class="token arrow operator">--&gt;</span> D<span class="token text string">[输入文本预处理&lt;br/&gt;get_token分词]</span>

    D <span class="token arrow operator">--&gt;</span> E<span class="token text string">[文本编码&lt;br/&gt;tokenizer编码]</span>
    E <span class="token arrow operator">--&gt;</span> F<span class="token text string">[模型推理&lt;br/&gt;model.forward]</span>
    F <span class="token arrow operator">--&gt;</span> G<span class="token text string">[结果后处理&lt;br/&gt;概率计算]</span>
    G <span class="token arrow operator">--&gt;</span> H<span class="token text string">[实体提取&lt;br/&gt;BIO标签解析]</span>

    H <span class="token arrow operator">--&gt;</span> I<span class="token text string">{验证模式}</span>
    I <span class="token arrow operator">--&gt;</span><span class="token label property">|单文本验证|</span> J<span class="token text string">[单个结果输出&lt;br/&gt;实体信息显示]</span>
    I <span class="token arrow operator">--&gt;</span><span class="token label property">|批量验证|</span> K<span class="token text string">[批量结果保存&lt;br/&gt;JSON格式输出]</span>
    I <span class="token arrow operator">--&gt;</span><span class="token label property">|交互式验证|</span> L<span class="token text string">[用户交互界面&lt;br/&gt;实时预测]</span>
    I <span class="token arrow operator">--&gt;</span><span class="token label property">|测试集验证|</span> M<span class="token text string">[测试数据评估&lt;br/&gt;性能指标计算]</span>

    <span class="token keyword">style</span> A <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FF6B6B<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> B <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#4ECDC4<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> C <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FFD93D<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#333</span>
    <span class="token keyword">style</span> D <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#6BCF7F<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> E <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#4D96FF<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> F <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#9B59B6<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>4px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> G <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#FF8C42<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> H <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#E74C3C<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>3px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> I <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#F39C12<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>4px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> J <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#1ABC9C<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> K <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#3498DB<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> L <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#8E44AD<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
    <span class="token keyword">style</span> M <span class="token style"><span class="token property">fill</span><span class="token operator">:</span>#2ECC71<span class="token punctuation">,</span><span class="token property">stroke</span><span class="token operator">:</span>#333<span class="token punctuation">,</span><span class="token property">stroke-width</span><span class="token operator">:</span>2px<span class="token punctuation">,</span><span class="token property">color</span><span class="token operator">:</span>#fff</span>
</code></pre><h3 id="验证核心代码" tabindex="-1">验证核心代码 <a class="header-anchor" href="#验证核心代码" aria-hidden="true">#</a></h3><h4 id="ner-预测核心函数" tabindex="-1">NER 预测核心函数 <a class="header-anchor" href="#ner-预测核心函数" aria-hidden="true">#</a></h4><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict_ner</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    对文本进行NER预测，提取命名实体

    Args:
        text: 输入文本
        model: 训练好的模型
        tokenizer: tokenizer实例

    Returns:
        预测结果列表，每个元素包含实体信息
    """</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token comment"># 1. 文本预处理和分词</span>
        input_char <span class="token operator">=</span> get_token<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

        <span class="token comment"># 2. Tokenizer编码</span>
        input_tensor <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
            input_char<span class="token punctuation">,</span>
            is_split_into_words<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>
            return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 3. 获取tokens和offset信息</span>
        input_tokens <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>tokens<span class="token punctuation">(</span><span class="token punctuation">)</span>
        offsets <span class="token operator">=</span> input_tensor<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span>
        ignore_mask <span class="token operator">=</span> offsets<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span>
        input_tensor<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span>

        <span class="token comment"># 4. 模型推理</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>input_tensor<span class="token punctuation">)</span>

        <span class="token comment"># 5. 计算概率和预测结果</span>
        probabilities <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        predictions <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 6. 解析BIO标签和实体提取</span>
        results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        idx <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token keyword">while</span> idx <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>predictions<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> ignore_mask<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">:</span>
                idx <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword">continue</span>

            pred <span class="token operator">=</span> predictions<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
            label <span class="token operator">=</span> model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label<span class="token punctuation">[</span>pred<span class="token punctuation">]</span>

            <span class="token keyword">if</span> label <span class="token operator">!=</span> <span class="token string">"O"</span><span class="token punctuation">:</span>
                <span class="token comment"># 提取实体类型和边界</span>
                entity_type <span class="token operator">=</span> label<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># 移除B-或I-前缀</span>
                start <span class="token operator">=</span> idx
                end <span class="token operator">=</span> start <span class="token operator">+</span> <span class="token number">1</span>

                <span class="token comment"># 处理连续的I-标签</span>
                <span class="token keyword">while</span> <span class="token punctuation">(</span>end <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>predictions<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token keyword">not</span> ignore_mask<span class="token punctuation">[</span>end<span class="token punctuation">]</span> <span class="token keyword">and</span>
                       model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label<span class="token punctuation">[</span>predictions<span class="token punctuation">[</span>end<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string-interpolation"><span class="token string">f"I-</span><span class="token interpolation"><span class="token punctuation">{</span>entity_type<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    end <span class="token operator">+=</span> <span class="token number">1</span>
                    idx <span class="token operator">+=</span> <span class="token number">1</span>

                <span class="token comment"># 计算置信度和构建实体信息</span>
                entity_tokens <span class="token operator">=</span> input_tokens<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span>
                entity_word <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>entity_tokens<span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"##"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>
                score <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">[</span>probabilities<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>predictions<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

                entity_info <span class="token operator">=</span> <span class="token punctuation">{</span>
                    <span class="token string">"entity_group"</span><span class="token punctuation">:</span> entity_type<span class="token punctuation">,</span> <span class="token string">"score"</span><span class="token punctuation">:</span> score<span class="token punctuation">,</span> <span class="token string">"word"</span><span class="token punctuation">:</span> entity_word<span class="token punctuation">,</span> <span class="token string">"tokens"</span><span class="token punctuation">:</span> entity_tokens<span class="token punctuation">,</span> <span class="token string">"start"</span><span class="token punctuation">:</span> start<span class="token punctuation">,</span> <span class="token string">"end"</span><span class="token punctuation">:</span> end<span class="token punctuation">,</span>
                <span class="token punctuation">}</span>
                results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>entity_info<span class="token punctuation">)</span>

            idx <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">return</span> results

    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"预测过程中发生错误: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">raise</span>

<span class="token comment"># 预测流程伪代码:</span>
<span class="token comment"># 输入: 原始文本</span>
<span class="token comment"># 1. 文本预处理 → 调用get_token进行分词</span>
<span class="token comment"># 2. Tokenizer编码 → 转换为模型输入格式</span>
<span class="token comment"># 3. 获取映射信息 → 处理子词分割和位置映射</span>
<span class="token comment"># 4. 模型推理 → 前向传播获取logits</span>
<span class="token comment"># 5. 概率计算 → softmax转换为概率分布</span>
<span class="token comment"># 6. 标签预测 → argmax获取最大概率标签</span>
<span class="token comment"># 7. BIO解析 → 识别实体边界(B-开始, I-内部)</span>
<span class="token comment"># 8. 实体合并 → 将连续token组合为完整实体</span>
<span class="token comment"># 9. 置信度计算 → 计算实体的平均置信度</span>
<span class="token comment"># 10. 结果构建 → 生成结构化实体信息</span>
<span class="token comment"># 输出: 实体列表[{type, word, score, position}]</span>
</code></pre><p><strong>功能说明</strong>:</p><ul><li><strong>智能分词</strong>: 使用与训练时相同的分词策略确保一致性</li><li><strong>模型推理</strong>: 通过 BERT 模型前向传播获取每个 token 的标签概率</li><li><strong>BIO 解析</strong>: 识别 B-标签(实体开始)和 I-标签(实体内部)，合并连续实体</li><li><strong>置信度计算</strong>: 对实体内所有 token 的预测概率取平均值</li><li><strong>结果结构化</strong>: 返回包含实体类型、文本、置信度和位置的完整信息</li></ul><h3 id="验证配置示例" tabindex="-1">验证配置示例 <a class="header-anchor" href="#验证配置示例" aria-hidden="true">#</a></h3><h4 id="config-json-验证配置部分" tabindex="-1">config.json 验证配置部分: <a class="header-anchor" href="#config-json-验证配置部分" aria-hidden="true">#</a></h4><pre class="language-json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"validation"</span><span class="token operator">:</span> <span class="token punctuation">{</span>
    <span class="token property">"model_path"</span><span class="token operator">:</span> <span class="token string">"./output/checkpoint-1000"</span><span class="token punctuation">,</span>
    <span class="token property">"tokenizer_path"</span><span class="token operator">:</span> <span class="token string">"bert-base-chinese"</span><span class="token punctuation">,</span>
    <span class="token property">"val_file"</span><span class="token operator">:</span> <span class="token string">"./data/val.txt"</span><span class="token punctuation">,</span>
    <span class="token property">"log_file"</span><span class="token operator">:</span> <span class="token string">"./logs/validation.log"</span><span class="token punctuation">,</span>
    <span class="token property">"log_level"</span><span class="token operator">:</span> <span class="token string">"INFO"</span><span class="token punctuation">,</span>
    <span class="token property">"output_dir"</span><span class="token operator">:</span> <span class="token string">"./validation_output"</span><span class="token punctuation">,</span>
    <span class="token property">"single_output_file"</span><span class="token operator">:</span> <span class="token string">"single_validation_results.json"</span><span class="token punctuation">,</span>
    <span class="token property">"batch_output_file"</span><span class="token operator">:</span> <span class="token string">"batch_validation_results.json"</span><span class="token punctuation">,</span>
    <span class="token property">"max_length"</span><span class="token operator">:</span> <span class="token number">512</span><span class="token punctuation">,</span>
    <span class="token property">"device"</span><span class="token operator">:</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
    <span class="token property">"default_test_texts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
      <span class="token string">"2009年高考在北京的报名费是2009元"</span><span class="token punctuation">,</span>
      <span class="token string">"2020年研究生考试在上海进行"</span><span class="token punctuation">,</span>
      <span class="token string">"明年的公务员考试将在广州举办"</span>
    <span class="token punctuation">]</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><h3 id="验证结果示例" tabindex="-1">验证结果示例 <a class="header-anchor" href="#验证结果示例" aria-hidden="true">#</a></h3><h4 id="单文本验证结果" tabindex="-1">单文本验证结果: <a class="header-anchor" href="#单文本验证结果" aria-hidden="true">#</a></h4><pre class="language-json"><code class="language-json"><span class="token punctuation">[</span>
  <span class="token punctuation">{</span>
    <span class="token property">"entity_group"</span><span class="token operator">:</span> <span class="token string">"year"</span><span class="token punctuation">,</span>
    <span class="token property">"score"</span><span class="token operator">:</span> <span class="token number">0.9876</span><span class="token punctuation">,</span>
    <span class="token property">"word"</span><span class="token operator">:</span> <span class="token string">"2009年"</span><span class="token punctuation">,</span>
    <span class="token property">"tokens"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"2009"</span><span class="token punctuation">,</span> <span class="token string">"年"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token property">"start"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
    <span class="token property">"end"</span><span class="token operator">:</span> <span class="token number">2</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span>
    <span class="token property">"entity_group"</span><span class="token operator">:</span> <span class="token string">"exam"</span><span class="token punctuation">,</span>
    <span class="token property">"score"</span><span class="token operator">:</span> <span class="token number">0.9654</span><span class="token punctuation">,</span>
    <span class="token property">"word"</span><span class="token operator">:</span> <span class="token string">"高考"</span><span class="token punctuation">,</span>
    <span class="token property">"tokens"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"高"</span><span class="token punctuation">,</span> <span class="token string">"考"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token property">"start"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token property">"end"</span><span class="token operator">:</span> <span class="token number">4</span>
  <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token punctuation">{</span>
    <span class="token property">"entity_group"</span><span class="token operator">:</span> <span class="token string">"location"</span><span class="token punctuation">,</span>
    <span class="token property">"score"</span><span class="token operator">:</span> <span class="token number">0.9432</span><span class="token punctuation">,</span>
    <span class="token property">"word"</span><span class="token operator">:</span> <span class="token string">"北京"</span><span class="token punctuation">,</span>
    <span class="token property">"tokens"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"北"</span><span class="token punctuation">,</span> <span class="token string">"京"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token property">"start"</span><span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
    <span class="token property">"end"</span><span class="token operator">:</span> <span class="token number">7</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre></div><!--]--><!--]--></div></article><div class="prose m-auto mt-8 mb-8"><a class="font-mono no-underline opacity-50 hover:opacity-75">cd ..</a></div><!--]--><div class="mt-10 mb-6 prose m-auto opacity-50 flex"><span class="text-sm"><a target="_blank" href="https://beian.miit.gov.cn" style="color:inherit">浙ICP备2021022773号 &nbsp;&nbsp; </a>2022-PRESENT © ZhengKe</span><div class="flex-auto"></div></div></main><!--]--></div><link rel="stylesheet" href="/assets/Post.63afffbd.css"><link rel="stylesheet" href="/assets/app.baf61519.css"></body></html>